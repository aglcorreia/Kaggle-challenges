{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as pyplot\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "import lightgbm as lgb\n",
    "import math\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "import datetime as dt\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "PATH = 'data/'\n",
    "#!ls ../input/ashrae-energy-prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reduce Memory function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "#Based on this great kernel https://www.kaggle.com/arjanso/reducing-dataframe-memory-size-by-65\n",
    "def reduce_mem_usage(df, verbose=False):\n",
    "    start_mem_usg = df.memory_usage().sum() / 1024**2 \n",
    "    if verbose:\n",
    "        print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
    "    for col in df.columns:\n",
    "        if df[col].dtype != object:  # Exclude strings      \n",
    "            if verbose:\n",
    "                # Print current column type\n",
    "                print(\"******************************\")\n",
    "                print(\"Column: \",col)\n",
    "                print(\"dtype before: \",df[col].dtype)            \n",
    "            # make variables for Int, max and min\n",
    "            IsInt = False\n",
    "            mx = df[col].max()\n",
    "            mn = df[col].min()\n",
    "            if verbose:\n",
    "                print(\"min for this col: \",mn)\n",
    "                print(\"max for this col: \",mx)\n",
    "            # Integer does not support NA, therefore, NA needs to be filled\n",
    "            if not np.isfinite(df[col]).all(): \n",
    "                NAlist.append(col)\n",
    "                df[col].fillna(mn-1,inplace=True)  \n",
    "                   \n",
    "            # test if column can be converted to an integer\n",
    "            asint = df[col].fillna(0).astype(np.int64)\n",
    "            result = (df[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result > -0.01 and result < 0.01:\n",
    "                IsInt = True            \n",
    "            # Make Integer/unsigned Integer datatypes\n",
    "            if IsInt:\n",
    "                if mn >= 0:\n",
    "                    if mx < 255:\n",
    "                        df[col] = df[col].astype(np.uint8)\n",
    "                    elif mx < 65535:\n",
    "                        df[col] = df[col].astype(np.uint16)\n",
    "                    elif mx < 4294967295:\n",
    "                        df[col] = df[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)    \n",
    "            # Make float datatypes 32 bit\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            \n",
    "            # Print new column type\n",
    "            if verbose:\n",
    "                print(\"dtype after: \",df[col].dtype)\n",
    "                print(\"******************************\")\n",
    "    # Print final result\n",
    "    if verbose:\n",
    "        print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "    mem_usg = df.memory_usage().sum() / 1024**2     \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")    \n",
    "    print(\"The dataframe is now \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    return df, NAlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSLE calculation** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    '''\n",
    "    A function to calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "    source: https://www.kaggle.com/marknagelberg/rmsle-function\n",
    "    '''\n",
    "    assert len(y) == len(y_pred)\n",
    "    terms_to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "    return (sum(terms_to_sum) * (1.0/len(y))) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: https://www.kaggle.com/bejeweled/ashrae-catboost-regressor\n",
    "def RMSLE(y_true, y_pred, *args, **kwargs):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag_feature(weather_df, window=3):\n",
    "    group_df = weather_df.groupby('site_id')\n",
    "    cols = ['air_temperature', 'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed']\n",
    "    rolled = group_df[cols].rolling(window=window, min_periods=0)\n",
    "    lag_mean = rolled.mean().reset_index().astype(np.float16)\n",
    "    lag_max = rolled.max().reset_index().astype(np.float16)\n",
    "    lag_min = rolled.min().reset_index().astype(np.float16)\n",
    "    lag_std = rolled.std().reset_index().astype(np.float16)\n",
    "    for col in cols:\n",
    "        weather_df[f'{col}_mean_lag{window}'] = lag_mean[col]\n",
    "        weather_df[f'{col}_max_lag{window}'] = lag_max[col]\n",
    "        weather_df[f'{col}_min_lag{window}'] = lag_min[col]\n",
    "        weather_df[f'{col}_std_lag{window}'] = lag_std[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_align(df):\n",
    "    df['offset'] = df.site_id.map(site_ids_offsets)\n",
    "    df['timestamp_aligned'] = (df.timestamp - pd.to_timedelta(df.offset, unit='H'))\n",
    "    df['timestamp'] = df['timestamp_aligned']\n",
    "    del df['timestamp_aligned']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_without_overflow_fast(col):\n",
    "    col /= len(col)\n",
    "    return col.mean() * len(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cyclic_feature(df, col, max_vals):\n",
    "    df[col + '_sin'] = np.sin(2 * np.pi * df[col]/max_vals)\n",
    "#     df[col + '_cos'] = np.cos(2 * np.pi * df[col]/max_vals)\n",
    "    del df[col]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "building_df = pd.read_csv(PATH+\"building_metadata.csv\")\n",
    "weather_train = pd.read_csv(PATH+\"weather_train.csv\", parse_dates=['timestamp'])\n",
    "weather_test = pd.read_csv(PATH+\"weather_test.csv\", parse_dates=['timestamp'])\n",
    "train = pd.read_csv(PATH+\"train.csv\", parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leak data loading and concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2260080\n"
     ]
    }
   ],
   "source": [
    "# load site 0 data\n",
    "leak_df = pd.read_pickle(PATH+'ucf-spider/site0.pkl') \n",
    "leak_df['meter_reading'] = leak_df.meter_reading_scraped\n",
    "leak_df.drop(['meter_reading_original','meter_reading_scraped'], axis=1, inplace=True)\n",
    "leak_df.fillna(0, inplace=True)\n",
    "leak_df.loc[leak_df.meter_reading < 0, 'meter_reading'] = 0\n",
    "leak_df = leak_df[leak_df.timestamp.dt.year > 2016]\n",
    "print(len(leak_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_2016=True\n",
    "if del_2016:\n",
    "    bids = leak_df.building_id.unique()\n",
    "    train = train[train.building_id.isin(bids) == False]\n",
    "\n",
    "leak_df = leak_df[leak_df.timestamp.dt.year.isin([2017,2018])]\n",
    "\n",
    "train = pd.concat([train, leak_df])\n",
    "train.reset_index(inplace=True)\n",
    "#weather_train = pd.concat([weather_train_df, weather_test_df])\n",
    "#weather_train_df.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.concat([weather_train,weather_test],ignore_index=True)\n",
    "weather_key = ['site_id', 'timestamp']\n",
    "\n",
    "temp_skeleton = weather[weather_key + ['air_temperature']].drop_duplicates(subset=weather_key).sort_values(by=weather_key).copy()\n",
    "\n",
    "# calculate ranks of hourly temperatures within date/site_id chunks\n",
    "temp_skeleton['temp_rank'] = temp_skeleton.groupby(['site_id', temp_skeleton.timestamp.dt.date])['air_temperature'].rank('average')\n",
    "\n",
    "# create a dataframe of site_ids (0-16) x mean hour rank of temperature within day (0-23)\n",
    "df_2d = temp_skeleton.groupby(['site_id', temp_skeleton.timestamp.dt.hour])['temp_rank'].mean().unstack(level=1)\n",
    "\n",
    "# Subtract the columnID of temperature peak by 14, getting the timestamp alignment gap.\n",
    "site_ids_offsets = pd.Series(df_2d.values.argmax(axis=1) - 14)\n",
    "site_ids_offsets.index.name = 'site_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train = timestamp_align(weather_train)\n",
    "weather_test = timestamp_align(weather_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_lag_feature(weather_train, window=3)\n",
    "add_lag_feature(weather_train, window=72)\n",
    "add_lag_feature(weather_test, window=3)\n",
    "add_lag_feature(weather_test, window=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaNs in weather data by interpolation\n",
    "weather_train = weather_train.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))\n",
    "weather_test = weather_test.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(building_df, left_on = \"building_id\", right_on = \"building_id\", how = \"left\")\n",
    "train = train.merge(weather_train, left_on = [\"site_id\", \"timestamp\"], right_on = [\"site_id\", \"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del weather_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = test.merge(weather_test, left_on = [\"timestamp\"], right_on = [\"timestamp\"])\n",
    "#del weather_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple FE: Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "#train[\"timestamp\"] = pd.to_datetime(train[\"timestamp\"])\n",
    "train[\"hour\"] = train[\"timestamp\"].dt.hour\n",
    "train[\"day\"] = train[\"timestamp\"].dt.day\n",
    "train[\"weekend\"] = train[\"timestamp\"].dt.weekday\n",
    "train[\"month\"] = train[\"timestamp\"].dt.month\n",
    "train[\"year\"] = train[\"timestamp\"].dt.year\n",
    "train['dayofweek'] = train['timestamp'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing weired data on site_id 0. This data looks weired until May 20. All electricity meter is 0 until May 20 for site_id == 0. I will remove these data from training data. It corresponds to building_id <= 104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Delete time stamp and encode ```primary_use```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(\"timestamp\", axis = 1)\n",
    "le = LabelEncoder()\n",
    "train[\"primary_use\"] = le.fit_transform(train[\"primary_use\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categoricals = [\"building_id\", \"primary_use\", \"hour\", \"day\", \"weekend\", \"month\", \"meter\", 'year']\n",
    "\n",
    "drop_cols = [\"precip_depth_1_hr\", \"sea_level_pressure\", \"wind_direction\", \"wind_speed\"]\n",
    "\n",
    "numericals = [\"square_feet\", \"year_built\", \"air_temperature\", \"cloud_coverage\",\n",
    "              \"dew_temperature\"]\n",
    "\n",
    "weather_lag_cols=['air_temperature_mean_lag3', 'air_temperature_max_lag3',\n",
    "       'air_temperature_min_lag3', 'air_temperature_std_lag3',\n",
    "       'cloud_coverage_mean_lag3', 'cloud_coverage_max_lag3',\n",
    "       'cloud_coverage_min_lag3', 'cloud_coverage_std_lag3',\n",
    "       'dew_temperature_mean_lag3', 'dew_temperature_max_lag3',\n",
    "       'dew_temperature_min_lag3', 'dew_temperature_std_lag3',\n",
    "       'precip_depth_1_hr_mean_lag3', 'precip_depth_1_hr_max_lag3',\n",
    "       'precip_depth_1_hr_min_lag3', 'precip_depth_1_hr_std_lag3',\n",
    "       'sea_level_pressure_mean_lag3', 'sea_level_pressure_max_lag3',\n",
    "       'sea_level_pressure_min_lag3', 'sea_level_pressure_std_lag3',\n",
    "       'wind_direction_mean_lag3', 'wind_direction_max_lag3',\n",
    "       'wind_direction_min_lag3', 'wind_direction_std_lag3',\n",
    "       'wind_speed_mean_lag3', 'wind_speed_max_lag3', 'wind_speed_min_lag3',\n",
    "       'wind_speed_std_lag3', 'air_temperature_mean_lag72',\n",
    "       'air_temperature_max_lag72', 'air_temperature_min_lag72',\n",
    "       'air_temperature_std_lag72', 'cloud_coverage_mean_lag72',\n",
    "       'cloud_coverage_max_lag72', 'cloud_coverage_min_lag72',\n",
    "       'cloud_coverage_std_lag72', 'dew_temperature_mean_lag72',\n",
    "       'dew_temperature_max_lag72', 'dew_temperature_min_lag72',\n",
    "       'dew_temperature_std_lag72', 'precip_depth_1_hr_mean_lag72',\n",
    "       'precip_depth_1_hr_max_lag72', 'precip_depth_1_hr_min_lag72',\n",
    "       'precip_depth_1_hr_std_lag72', 'sea_level_pressure_mean_lag72',\n",
    "       'sea_level_pressure_max_lag72', 'sea_level_pressure_min_lag72',\n",
    "       'sea_level_pressure_std_lag72', 'wind_direction_mean_lag72',\n",
    "       'wind_direction_max_lag72', 'wind_direction_min_lag72',\n",
    "       'wind_direction_std_lag72', 'wind_speed_mean_lag72',\n",
    "       'wind_speed_max_lag72', 'wind_speed_min_lag72', 'wind_speed_std_lag72']\n",
    "\n",
    "feat_cols = categoricals + numericals + weather_lag_cols[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.log1p(train[\"meter_reading\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(drop_cols + [\"site_id\",\"floor_count\",\"meter_reading\"], axis = 1)\n",
    "#train.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage is:  4738.387724876404  MB\n",
      "The dataframe is now  108.75 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "train, NAlist = reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values - Fill with mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = (100-train.count() / len(train) * 100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = (100-train.count() / len(train) * 100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_features = train.loc[:, missing_values > 0.0]\n",
    "missing_features = missing_features.apply(mean_without_overflow_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in train.loc[:, missing_values > 0.0].keys():\n",
    "    if key == 'year_built' or key == 'floor_count':\n",
    "        train[key].fillna(math.floor(missing_features[key]), inplace=True)\n",
    "        #test[key].fillna(math.floor(missing_features[key]), inplace=True)\n",
    "    else:\n",
    "        train[key].fillna(missing_features[key], inplace=True)\n",
    "        #test[key].fillna(missing_features[key], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = np.log1p(train[\"meter_reading\"])\n",
    "# raw_target = np.expm1(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training FOLD  0 \n",
      "\n",
      "Train index: \tfrom: 0 \tto: 19036626\n",
      "Valid index: \tfrom: 1 \tto: 19036625 \n",
      "\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[20]\ttraining's rmse: 1.55648\tvalid_1's rmse: 1.55673\n",
      "[40]\ttraining's rmse: 1.43033\tvalid_1's rmse: 1.43078\n",
      "[60]\ttraining's rmse: 1.36326\tvalid_1's rmse: 1.364\n",
      "[80]\ttraining's rmse: 1.31716\tvalid_1's rmse: 1.31772\n",
      "[100]\ttraining's rmse: 1.28167\tvalid_1's rmse: 1.28229\n",
      "[120]\ttraining's rmse: 1.25104\tvalid_1's rmse: 1.25162\n",
      "[140]\ttraining's rmse: 1.2252\tvalid_1's rmse: 1.22582\n",
      "[160]\ttraining's rmse: 1.19995\tvalid_1's rmse: 1.20064\n",
      "[180]\ttraining's rmse: 1.18008\tvalid_1's rmse: 1.18081\n",
      "[200]\ttraining's rmse: 1.16378\tvalid_1's rmse: 1.16455\n",
      "[220]\ttraining's rmse: 1.14361\tvalid_1's rmse: 1.14439\n",
      "[240]\ttraining's rmse: 1.12829\tvalid_1's rmse: 1.12911\n",
      "[260]\ttraining's rmse: 1.10962\tvalid_1's rmse: 1.11048\n",
      "[280]\ttraining's rmse: 1.09501\tvalid_1's rmse: 1.09596\n",
      "[300]\ttraining's rmse: 1.08027\tvalid_1's rmse: 1.08123\n",
      "[320]\ttraining's rmse: 1.06579\tvalid_1's rmse: 1.0667\n",
      "[340]\ttraining's rmse: 1.05217\tvalid_1's rmse: 1.05314\n",
      "[360]\ttraining's rmse: 1.04191\tvalid_1's rmse: 1.0429\n",
      "[380]\ttraining's rmse: 1.03265\tvalid_1's rmse: 1.03373\n",
      "[400]\ttraining's rmse: 1.02313\tvalid_1's rmse: 1.02425\n",
      "[420]\ttraining's rmse: 1.01349\tvalid_1's rmse: 1.01467\n",
      "[440]\ttraining's rmse: 1.00484\tvalid_1's rmse: 1.00603\n",
      "[460]\ttraining's rmse: 0.997483\tvalid_1's rmse: 0.998741\n",
      "[480]\ttraining's rmse: 0.989834\tvalid_1's rmse: 0.991156\n",
      "[500]\ttraining's rmse: 0.981739\tvalid_1's rmse: 0.983041\n",
      "[520]\ttraining's rmse: 0.975733\tvalid_1's rmse: 0.977078\n",
      "[540]\ttraining's rmse: 0.968108\tvalid_1's rmse: 0.969456\n",
      "[560]\ttraining's rmse: 0.961483\tvalid_1's rmse: 0.962844\n",
      "[580]\ttraining's rmse: 0.954298\tvalid_1's rmse: 0.955629\n",
      "[600]\ttraining's rmse: 0.947292\tvalid_1's rmse: 0.948782\n",
      "[620]\ttraining's rmse: 0.94174\tvalid_1's rmse: 0.943222\n",
      "[640]\ttraining's rmse: 0.935438\tvalid_1's rmse: 0.936941\n",
      "[660]\ttraining's rmse: 0.930588\tvalid_1's rmse: 0.932159\n",
      "[680]\ttraining's rmse: 0.924595\tvalid_1's rmse: 0.926255\n",
      "[700]\ttraining's rmse: 0.921283\tvalid_1's rmse: 0.92296\n",
      "[720]\ttraining's rmse: 0.916025\tvalid_1's rmse: 0.917731\n",
      "[740]\ttraining's rmse: 0.912253\tvalid_1's rmse: 0.914022\n",
      "[760]\ttraining's rmse: 0.906131\tvalid_1's rmse: 0.90797\n",
      "[780]\ttraining's rmse: 0.901764\tvalid_1's rmse: 0.90364\n",
      "[800]\ttraining's rmse: 0.89787\tvalid_1's rmse: 0.89981\n",
      "[820]\ttraining's rmse: 0.892779\tvalid_1's rmse: 0.894691\n",
      "[840]\ttraining's rmse: 0.888172\tvalid_1's rmse: 0.890136\n",
      "[860]\ttraining's rmse: 0.884009\tvalid_1's rmse: 0.886023\n",
      "[880]\ttraining's rmse: 0.879306\tvalid_1's rmse: 0.881397\n",
      "[900]\ttraining's rmse: 0.874561\tvalid_1's rmse: 0.876629\n",
      "[920]\ttraining's rmse: 0.8715\tvalid_1's rmse: 0.873595\n",
      "[940]\ttraining's rmse: 0.867948\tvalid_1's rmse: 0.870069\n",
      "[960]\ttraining's rmse: 0.865213\tvalid_1's rmse: 0.867363\n",
      "[980]\ttraining's rmse: 0.86206\tvalid_1's rmse: 0.864245\n",
      "[1000]\ttraining's rmse: 0.859115\tvalid_1's rmse: 0.861327\n",
      "[1020]\ttraining's rmse: 0.85636\tvalid_1's rmse: 0.858647\n",
      "[1040]\ttraining's rmse: 0.852694\tvalid_1's rmse: 0.854988\n",
      "[1060]\ttraining's rmse: 0.850664\tvalid_1's rmse: 0.852958\n",
      "[1080]\ttraining's rmse: 0.847909\tvalid_1's rmse: 0.850251\n",
      "[1100]\ttraining's rmse: 0.844901\tvalid_1's rmse: 0.847264\n",
      "[1120]\ttraining's rmse: 0.841852\tvalid_1's rmse: 0.844252\n",
      "[1140]\ttraining's rmse: 0.839517\tvalid_1's rmse: 0.841947\n",
      "[1160]\ttraining's rmse: 0.836443\tvalid_1's rmse: 0.838921\n",
      "[1180]\ttraining's rmse: 0.833817\tvalid_1's rmse: 0.836268\n",
      "[1200]\ttraining's rmse: 0.830692\tvalid_1's rmse: 0.833168\n",
      "[1220]\ttraining's rmse: 0.827833\tvalid_1's rmse: 0.830352\n",
      "[1240]\ttraining's rmse: 0.825259\tvalid_1's rmse: 0.827786\n",
      "[1260]\ttraining's rmse: 0.823179\tvalid_1's rmse: 0.825744\n",
      "[1280]\ttraining's rmse: 0.821175\tvalid_1's rmse: 0.823745\n",
      "[1300]\ttraining's rmse: 0.819159\tvalid_1's rmse: 0.821741\n",
      "[1320]\ttraining's rmse: 0.816001\tvalid_1's rmse: 0.818611\n",
      "[1340]\ttraining's rmse: 0.813655\tvalid_1's rmse: 0.816344\n",
      "[1360]\ttraining's rmse: 0.811634\tvalid_1's rmse: 0.814317\n",
      "[1380]\ttraining's rmse: 0.809746\tvalid_1's rmse: 0.812487\n",
      "[1400]\ttraining's rmse: 0.807777\tvalid_1's rmse: 0.810566\n",
      "[1420]\ttraining's rmse: 0.805827\tvalid_1's rmse: 0.808656\n",
      "[1440]\ttraining's rmse: 0.803821\tvalid_1's rmse: 0.806662\n",
      "[1460]\ttraining's rmse: 0.801586\tvalid_1's rmse: 0.80445\n",
      "[1480]\ttraining's rmse: 0.799251\tvalid_1's rmse: 0.802177\n",
      "[1500]\ttraining's rmse: 0.796463\tvalid_1's rmse: 0.799398\n",
      "[1520]\ttraining's rmse: 0.793808\tvalid_1's rmse: 0.796739\n",
      "[1540]\ttraining's rmse: 0.792121\tvalid_1's rmse: 0.795086\n",
      "[1560]\ttraining's rmse: 0.790164\tvalid_1's rmse: 0.793161\n",
      "[1580]\ttraining's rmse: 0.787997\tvalid_1's rmse: 0.791014\n",
      "[1600]\ttraining's rmse: 0.786011\tvalid_1's rmse: 0.789048\n",
      "[1620]\ttraining's rmse: 0.783922\tvalid_1's rmse: 0.786984\n",
      "[1640]\ttraining's rmse: 0.781968\tvalid_1's rmse: 0.785058\n",
      "[1660]\ttraining's rmse: 0.779579\tvalid_1's rmse: 0.782706\n",
      "[1680]\ttraining's rmse: 0.777534\tvalid_1's rmse: 0.780676\n",
      "[1700]\ttraining's rmse: 0.775253\tvalid_1's rmse: 0.778404\n",
      "[1720]\ttraining's rmse: 0.773671\tvalid_1's rmse: 0.776858\n",
      "[1740]\ttraining's rmse: 0.772335\tvalid_1's rmse: 0.775548\n",
      "[1760]\ttraining's rmse: 0.771204\tvalid_1's rmse: 0.774434\n",
      "[1780]\ttraining's rmse: 0.7694\tvalid_1's rmse: 0.772627\n",
      "[1800]\ttraining's rmse: 0.767891\tvalid_1's rmse: 0.771147\n",
      "[1820]\ttraining's rmse: 0.766398\tvalid_1's rmse: 0.769688\n",
      "[1840]\ttraining's rmse: 0.765121\tvalid_1's rmse: 0.768434\n",
      "[1860]\ttraining's rmse: 0.763693\tvalid_1's rmse: 0.76705\n",
      "[1880]\ttraining's rmse: 0.761712\tvalid_1's rmse: 0.765077\n",
      "[1900]\ttraining's rmse: 0.759787\tvalid_1's rmse: 0.763216\n",
      "[1920]\ttraining's rmse: 0.757947\tvalid_1's rmse: 0.761399\n",
      "[1940]\ttraining's rmse: 0.756575\tvalid_1's rmse: 0.760032\n",
      "[1960]\ttraining's rmse: 0.754848\tvalid_1's rmse: 0.758326\n",
      "[1980]\ttraining's rmse: 0.753283\tvalid_1's rmse: 0.756789\n",
      "[2000]\ttraining's rmse: 0.751704\tvalid_1's rmse: 0.755243\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.751704\tvalid_1's rmse: 0.755243\n",
      "\n",
      "Fold 0  Score:  0.7552428930821536\n",
      "------------------------------------------------------------\n",
      "CV error:  0.15104857861643073\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "kf = KFold(n_splits = num_folds, shuffle = True, random_state = 42)\n",
    "error = 0\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train, target)):\n",
    "\n",
    "    print ('Training FOLD ',fold,'\\n')\n",
    "    print('Train index:','\\tfrom:',train_index.min(),'\\tto:',train_index.max())\n",
    "    print('Valid index:','\\tfrom:',val_index.min(),'\\tto:',val_index.max(),'\\n')\n",
    "    \n",
    "    train_X = train[feat_cols].iloc[train_index]\n",
    "    val_X = train[feat_cols].iloc[val_index]\n",
    "    train_y = target.iloc[train_index]\n",
    "    val_y = target.iloc[val_index]\n",
    "    lgb_train = lgb.Dataset(train_X, train_y)\n",
    "    lgb_eval = lgb.Dataset(val_X, val_y)\n",
    "    \n",
    "    params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': {'rmse'},\n",
    "            'learning_rate': 0.1,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.9\n",
    "            }\n",
    "    \n",
    "    gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=2000,\n",
    "                valid_sets=(lgb_train, lgb_eval),\n",
    "               early_stopping_rounds=20,\n",
    "               verbose_eval = 20)\n",
    "\n",
    "    y_pred = gbm.predict(val_X, num_iteration=gbm.best_iteration)\n",
    "    error += np.sqrt(mean_squared_error(y_pred, (val_y)))/num_folds\n",
    "    \n",
    "    print('\\nFold',fold,' Score: ',np.sqrt(mean_squared_error(y_pred, val_y)))\n",
    "    #print('RMSLE: ', rmsle(y_pred, val_y))\n",
    "    #print('RMSLE_2: ', np.sqrt(mean_squared_log_error(y_pred, (val_y))))\n",
    "\n",
    "    del train_X, val_X, train_y, val_y, lgb_train, lgb_eval\n",
    "    gc.collect()\n",
    "\n",
    "    print (20*'---')\n",
    "    break\n",
    "    \n",
    "print('CV error: ',error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory allocation\n",
    "#del train, target\n",
    "del target\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(PATH+\"/test.csv\", parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(building_df, left_on = \"building_id\", right_on = \"building_id\", how = \"left\")\n",
    "test = test.merge(weather_test, left_on = [\"site_id\", \"timestamp\"], right_on = [\"site_id\", \"timestamp\"], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del weather_test\n",
    "del building_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "test[\"primary_use\"] = le.transform(test[\"primary_use\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change dates type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "#test[\"timestamp\"] = pd.to_datetime(test[\"timestamp\"])\n",
    "test[\"hour\"] = test[\"timestamp\"].dt.hour.astype(np.uint8)\n",
    "test[\"day\"] = test[\"timestamp\"].dt.day.astype(np.uint8)\n",
    "test[\"weekend\"] = test[\"timestamp\"].dt.weekday.astype(np.uint8)\n",
    "test[\"month\"] = test[\"timestamp\"].dt.month.astype(np.uint8)\n",
    "test[\"year\"] = test[\"timestamp\"].dt.year.astype(np.uint8)\n",
    "test['dayofweek'] = test['timestamp'].dt.dayofweek.astype(np.uint8)\n",
    "\n",
    "test = test[feat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in train.loc[:, missing_values > 0.0].keys():\n",
    "    if key == 'year_built' or key == 'floor_count':\n",
    "        #train[key].fillna(math.floor(missing_features[key]), inplace=True)\n",
    "        test[key].fillna(math.floor(missing_features[key]), inplace=True)\n",
    "    else:\n",
    "        #train[key].fillna(missing_features[key], inplace=True)\n",
    "        test[key].fillna(missing_features[key], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reduce Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage is:  4573.081970214844  MB\n",
      "The dataframe is now  98.2905982905983 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "test, NAlist = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del weather, weather_key, train_index, val_index\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>weekend</th>\n",
       "      <th>month</th>\n",
       "      <th>meter</th>\n",
       "      <th>year</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>...</th>\n",
       "      <th>dew_temperature_min_lag3</th>\n",
       "      <th>dew_temperature_std_lag3</th>\n",
       "      <th>precip_depth_1_hr_mean_lag3</th>\n",
       "      <th>precip_depth_1_hr_max_lag3</th>\n",
       "      <th>precip_depth_1_hr_min_lag3</th>\n",
       "      <th>precip_depth_1_hr_std_lag3</th>\n",
       "      <th>sea_level_pressure_mean_lag3</th>\n",
       "      <th>sea_level_pressure_max_lag3</th>\n",
       "      <th>sea_level_pressure_min_lag3</th>\n",
       "      <th>sea_level_pressure_std_lag3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>12.796875</td>\n",
       "      <td>0.288574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1022.5</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.099976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>2720</td>\n",
       "      <td>2004</td>\n",
       "      <td>...</td>\n",
       "      <td>12.796875</td>\n",
       "      <td>0.288574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1022.5</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.099976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>5376</td>\n",
       "      <td>1991</td>\n",
       "      <td>...</td>\n",
       "      <td>12.796875</td>\n",
       "      <td>0.288574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1022.5</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.099976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>23685</td>\n",
       "      <td>2002</td>\n",
       "      <td>...</td>\n",
       "      <td>12.796875</td>\n",
       "      <td>0.288574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1022.5</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.099976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>116607</td>\n",
       "      <td>1975</td>\n",
       "      <td>...</td>\n",
       "      <td>12.796875</td>\n",
       "      <td>0.288574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1022.5</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.099976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  primary_use  hour  day  weekend  month  meter  year  \\\n",
       "0            0            0     0    1        6      1      0   225   \n",
       "1            1            0     0    1        6      1      0   225   \n",
       "2            2            0     0    1        6      1      0   225   \n",
       "3            3            0     0    1        6      1      0   225   \n",
       "4            4            0     0    1        6      1      0   225   \n",
       "\n",
       "   square_feet  year_built  ...  dew_temperature_min_lag3  \\\n",
       "0         7432        2008  ...                 12.796875   \n",
       "1         2720        2004  ...                 12.796875   \n",
       "2         5376        1991  ...                 12.796875   \n",
       "3        23685        2002  ...                 12.796875   \n",
       "4       116607        1975  ...                 12.796875   \n",
       "\n",
       "   dew_temperature_std_lag3  precip_depth_1_hr_mean_lag3  \\\n",
       "0                  0.288574                          0.0   \n",
       "1                  0.288574                          0.0   \n",
       "2                  0.288574                          0.0   \n",
       "3                  0.288574                          0.0   \n",
       "4                  0.288574                          0.0   \n",
       "\n",
       "   precip_depth_1_hr_max_lag3  precip_depth_1_hr_min_lag3  \\\n",
       "0                         0.0                         0.0   \n",
       "1                         0.0                         0.0   \n",
       "2                         0.0                         0.0   \n",
       "3                         0.0                         0.0   \n",
       "4                         0.0                         0.0   \n",
       "\n",
       "   precip_depth_1_hr_std_lag3  sea_level_pressure_mean_lag3  \\\n",
       "0                         0.0                        1022.0   \n",
       "1                         0.0                        1022.0   \n",
       "2                         0.0                        1022.0   \n",
       "3                         0.0                        1022.0   \n",
       "4                         0.0                        1022.0   \n",
       "\n",
       "   sea_level_pressure_max_lag3  sea_level_pressure_min_lag3  \\\n",
       "0                       1022.5                       1022.0   \n",
       "1                       1022.5                       1022.0   \n",
       "2                       1022.5                       1022.0   \n",
       "3                       1022.5                       1022.0   \n",
       "4                       1022.5                       1022.0   \n",
       "\n",
       "   sea_level_pressure_std_lag3  \n",
       "0                     0.099976  \n",
       "1                     0.099976  \n",
       "2                     0.099976  \n",
       "3                     0.099976  \n",
       "4                     0.099976  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 834/834 [16:04<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "i=0\n",
    "res=[]\n",
    "step_size = 50000 \n",
    "for j in tqdm(range(int(np.ceil(test.shape[0]/50000)))):\n",
    "    res.append(np.expm1(gbm.predict(test.iloc[i:i+step_size])))\n",
    "    i+=step_size"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "source": [
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.295210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.518826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8.054509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>55.583306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>557.602135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>8.930230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>68.643231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>350.519425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>110.846266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>186.549073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  meter_reading\n",
       "0       0       8.295210\n",
       "1       1       4.518826\n",
       "2       2       8.054509\n",
       "3       3      55.583306\n",
       "4       4     557.602135\n",
       "5       5       8.930230\n",
       "6       6      68.643231\n",
       "7       7     350.519425\n",
       "8       8     110.846266\n",
       "9       9     186.549073"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.concatenate(res)\n",
    "sub = pd.read_csv(PATH+\"sample_submission.csv\")\n",
    "sub[\"meter_reading\"] = res\n",
    "sub.to_csv(\"submission.csv\", index = False)\n",
    "sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41697600,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41697600, 33)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41697600, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.round(1).to_csv(\"submission_rounded.csv.gz\", index = False, compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
